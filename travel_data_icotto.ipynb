{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "travel_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWFQSMqay/1Ue3k/kdRSFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Launcha10/sports_entertaiment_topic_analysis/blob/hayashi-test/travel_data_icotto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1aLzcrdIfWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pNcAZBhfQvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install chardet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSjzg6X2N6bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN8kw3jOkmgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####URLをスクレイピングして、リンク先をスクレイピング"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS155hVqkmlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#スクレイピング1回目(リンク)\n",
        "base_url = \"https://icotto.jp/keywords/1138?page=%s\"\n",
        "\n",
        "#1~4ページをの記事を取得\n",
        "for page in range(1,100):\n",
        "\n",
        "    #1秒間隔\n",
        "    time.sleep(1)\n",
        "    print(page)\n",
        "\n",
        "    r = requests.get(base_url%page)\n",
        "    soup = BeautifulSoup(r.content,'lxml')\n",
        "\n",
        "    #aタグ、クラスc-presses-standard__linkのhref要素のみ抽出\n",
        "    links = [tag.get('href') for tag in soup('a', class_=\"c-presses-standard__link\")]\n",
        "\n",
        "\n",
        "    #noneを削除\n",
        "    none_links = [item for item in links if item]\n",
        "    #リスト内のurlの重複を消す\n",
        "    set_links = set(none_links)\n",
        "    #リンク内のランキングにまつわる余計なurlを消す\n",
        "    rank_links1 = [s for s in set_links if 'lid' not in s]\n",
        "    rank_links2 = [s for s in rank_links1 if '17735' not in s]\n",
        "    rank_links3 = [s for s in rank_links2 if '17734' not in s]\n",
        "    rank_links4 = [s for s in rank_links3 if '17733' not in s]\n",
        "\n",
        "    i = 1\n",
        "    #exec(\"data\" + str(page) + \"= []\")\n",
        "    #data = []\n",
        "\n",
        "    for link in rank_links4:\n",
        "        url_link = 'https://icotto.jp'+ link\n",
        "\n",
        "        #print(url_link)\n",
        "        \n",
        "        #スクレイピング2回目\n",
        "        r2 = requests.get(url_link)\n",
        "        soup2 = BeautifulSoup(r2.content,'lxml')\n",
        "        \n",
        "        #print(soup2)\n",
        "\n",
        "        exec(\"data\" + str(page) + \"_\" + str(i) + \"= [tag2.text for tag2 in soup2('p')]\")\n",
        "        i += 1\n",
        "        #exec(\"data\" + str(page) + \"+= [tag2.text for tag2 in soup2('p')]\")\n",
        "        #data += [tag2.text for tag2 in soup2('p')]\n",
        "\n",
        "        #1秒間隔\n",
        "        time.sleep(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLFq2UW7rbd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#フォーマットしたstr型に変更\n",
        "import pprint\n",
        "for n in range(1,100):\n",
        "    for i in range(1, 31):\n",
        "\n",
        "      exec(\"str_data%d_%d = pprint.pformat(data%d_%d)\" % (n,i,n,i))\n",
        "      #str_data = pprint.pformat(data)\n",
        "    \n",
        "print(str_data99_30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4WCWFNb0AFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "#文章の整形関数\n",
        "def format_text(text):\n",
        "\n",
        "    text=re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
        "    text=re.sub('あわせて読む', \"\", text)\n",
        "    text=re.sub('データ提供', \"\", text)\n",
        "    text=re.sub('出典', \"\", text)\n",
        "    text=re.sub('さんの投稿', \"\", text)\n",
        "    text=re.sub('円', \"\", text)\n",
        "    ext=re.sub('イコット', \"\", text)\n",
        "    ext=re.sub('人', \"\", text)\n",
        "    ext=re.sub('引用元', \"\", text)\n",
        "    text=re.sub(r'[!-~]', \"\", text)#半角記号,数字,英字\n",
        "    text=re.sub(r'[︰-＠]', \"\", text)#全角記号\n",
        "    #text=re.sub('\\n', \" \", text)#改行文字\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RnDJvg1s7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(1,100):\n",
        "    for i in range(1,31):\n",
        "       exec(\"text%d_%d = format_text(str_data%d_%d)\" % (n,i,n,i))\n",
        "\n",
        "#print(type(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAa1zJEB0zB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(1,100):\n",
        "    for i in range(1, 31):\n",
        "        exec(\"lines%d_%d = [line.strip() for line in text%d_%d.splitlines()]\" % (n,i,n,i))\n",
        "        #lines = [line.strip() for line in text.splitlines()]\n",
        "\n",
        "#print(lines99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVXR0EB90z3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(1,100):\n",
        "    for i in range(1,31):\n",
        "        exec('format_text%d_%d = \"\"\"\\n\"\"\".join(line for line in lines%d_%d if line)' % (n,i,n,i))\n",
        "\n",
        "#print(format_text99_30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zk5Rz4uGHG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(1,100):\n",
        "    for i in range(1,31):\n",
        "        file = open('/content/drive/My Drive/ernie/travel_data/new_new_text/text3/text%d_%d.txt' % (n,i), 'w')\n",
        "        exec(\"file.write(format_text%d_%d)\" % (n,i))\n",
        "        file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}